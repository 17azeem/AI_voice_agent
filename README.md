# ğŸ—¨ï¸ AI Voice Chat Agent

Talk to an AI using your voice with this interactive AI Voice Chat Agent. It uses your microphone for real-time conversation, powered by Google Gemini, AssemblyAI for speech-to-text, and Murf TTS for natural-sounding voice output. This project is ideal for creating smart assistants, conversational chatbots, or voice-based applications.

ğŸ‘‰ Now enhanced with a **News Skill** powered by **Tavily** â€“ so you can ask it for the **latest AI news with links to sources**. 

## ğŸ¯ How It Works

1. ğŸ™ï¸ Speak into your mic â†’ Browser captures audio.
2. ğŸ”Š STT (AssemblyAI) transcribes speech into text.
3. ğŸ§  AI (Gemini 2.5) generates a relevant response.
4. ğŸ§ TTS (Murf AI) turns the response into speech.
5. â™¾ï¸ Loop â€“ The AI listens again for your reply.

## Screenshots

![1.](./frontend/images/ss1.png)
![2.](./frontend/images/ss2.png)

## ğŸ› ï¸ Tech Stack

### ğŸ”¹ Frontend  
- HTML, CSS, JavaScript  
- Web Audio API (microphone streaming + playback)  

### ğŸ”¹ Backend  
- FastAPI (Python)  

### ğŸ”¹ AI / Speech Services  
- **Google Gemini 2.5 Flash** â†’ Conversational AI  
- **AssemblyAI** â†’ Speech-to-Text  
- **Murf AI** â†’ Text-to-Speech  
- **Tavily** â†’ AI news fetcher 

## ğŸ“‚ Project Structure
```
backend/
  app/
    core/
      config.py            # env + constants
      logging_config.py    # logging setup
    routers/
      chat.py              # /agent/chat endpoint
      transcriber.py
    schemas/
      chat.py              # pydantic response models
    services/
      stt_service.py       # AssemblyAI transcription
      tts_service.py       # Murf TTS synthesis
      llm_service.py       # Gemini chat
    main.py                # FastAPI app factory & router wiring
  static/
    images
    index.html
    script.js
    style.css
  run.py                   # uvicorn entry

venv
.env  
```

## ğŸ“¦ Dependencies

fastapi
uvicorn
requests
python-dotenv
google-genai
assemblyai
tavily-python

## Environment
Create a `.env` in project root:
```
GEMINI_API_KEY=...
MURF_API_KEY=...
ASSEMBLYAI_API_KEY=...
TAVILY_API_KEY=...
STATIC_DIR=./frontend
```

## Install Backend Dependencies
```bash
cd backend
pip install -r requirements.txt

```

## Run the Backend Server
```bash

uvicorn app.main:app --reload

```

Open: http://localhost:8000/
Static files served from `/static` â†’ `frontend/`.

## ğŸŒ Hosted Version  

The project is deployed on **Render**.  

ğŸ‘‰ **Hosted Link**: [https://ranchobytes-ai.onrender.com/](https://ranchobytes-ai.onrender.com/)  
 
---

### ğŸ”‘ Usage on Hosted Version  

1. Enter your **API keys** inside the web UI input fields.  
2. Click **Start** â†’ Begin voice chat with the AI.  
3. Try example queries:  
   - â€œTell me a joke.â€  
   - â€œAI newsâ€ â†’ Returns headlines + clickable link.  



## ğŸ’¡ Author

*Mohd Azeem* | https://github.com/17azeem
